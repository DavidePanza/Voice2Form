{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81b996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a01223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import audeer\n",
    "import audonnx\n",
    "import audinterface\n",
    "from modal import App, Image, web_endpoint, Volume\n",
    "from fastapi import FastAPI, HTTPException, File, UploadFile, Form\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "# Create the Modal app\n",
    "app = App(\"voice-analysis-api\")\n",
    "\n",
    "# Create a persistent volume for model storage\n",
    "model_volume = Volume.from_name(\"voice-analysis-models\", create_if_missing=True)\n",
    "\n",
    "# Define the container image with all dependencies\n",
    "image = (\n",
    "    Image.debian_slim(python_version=\"3.10\")\n",
    "    .pip_install([\n",
    "        \"audeer\",\n",
    "        \"audonnx\", \n",
    "        \"audinterface\",\n",
    "        \"librosa\",\n",
    "        \"numpy\",\n",
    "        \"pandas\",\n",
    "        \"fastapi\",\n",
    "        \"python-multipart\",\n",
    "        \"soundfile\"\n",
    "    ])\n",
    "    .apt_install([\"ffmpeg\"])\n",
    "    # Download model during image build\n",
    "    .run_commands([\n",
    "        \"mkdir -p /model_cache\",\n",
    "        \"python -c \\\"import audeer; audeer.download_url('https://zenodo.org/record/6221127/files/w2v2-L-robust-12.6bc4a7fd-1.1.0.zip', '/model_cache/model.zip', verbose=True)\\\"\",\n",
    "        \"python -c \\\"import audeer; audeer.extract_archive('/model_cache/model.zip', '/model_cache/model', verbose=True)\\\"\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Mount local files if needed (optional)\n",
    "# mount = Mount.from_local_dir(\"./\", remote_path=\"/app\")\n",
    "\n",
    "@app.function(\n",
    "    image=image,\n",
    "    volumes={\"/persistent_model\": model_volume},  # Mount persistent volume\n",
    "    timeout=300,  # 5 minutes timeout\n",
    "    memory=2048,  # 2GB memory\n",
    "    cpu=2.0,\n",
    "    # Removed keep_warm for cost optimization\n",
    "    # Cold start will be ~5-10 seconds but no continuous billing\n",
    "    concurrency_limit=10,  # Allow multiple concurrent requests\n",
    "    allow_concurrent_inputs=100,  # Queue up to 100 requests\n",
    ")\n",
    "@web_endpoint(method=\"POST\", docs=True)\n",
    "def analyze_voice_endpoint(\n",
    "    audio_file: UploadFile = File(...),\n",
    "    window_size: float = Form(default=1.0),\n",
    "    hop_size: float = Form(default=0.25)\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze voice for VAD (Valence, Arousal, Dominance) + envelope extraction\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_file: Audio file (WAV, MP3, etc.)\n",
    "    - window_size: Analysis window size in seconds (default: 1.0)\n",
    "    - hop_size: Hop size between windows in seconds (default: 0.25)\n",
    "    \n",
    "    Returns:\n",
    "    - JSON with frame-by-frame analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and process the uploaded audio file\n",
    "        audio_bytes = audio_file.file.read()\n",
    "        \n",
    "        # Load audio using librosa\n",
    "        audio, sr = librosa.load(io.BytesIO(audio_bytes), sr=16000, mono=True)\n",
    "        \n",
    "        # Load the official model (with caching)\n",
    "        model, interface = load_official_model()\n",
    "        \n",
    "        # Analyze the audio\n",
    "        results = predict_vad_frames_with_envelope_official(\n",
    "            audio, interface, window_size, hop_size\n",
    "        )\n",
    "        \n",
    "        # Format results for JSON response\n",
    "        response_data = {\n",
    "            \"status\": \"success\",\n",
    "            \"metadata\": {\n",
    "                \"total_frames\": len(results['times']),\n",
    "                \"window_size\": results['window_size'],\n",
    "                \"hop_size\": results['hop_size'],\n",
    "                \"audio_duration\": len(audio) / sr,\n",
    "                \"sample_rate\": sr\n",
    "            },\n",
    "            \"frames\": []\n",
    "        }\n",
    "        \n",
    "        # Add frame-by-frame results\n",
    "        for i in range(len(results['times'])):\n",
    "            frame_data = {\n",
    "                \"frame_index\": i,\n",
    "                \"time\": float(results['times'][i]),\n",
    "                \"valence\": float(results['valence'][i]),\n",
    "                \"arousal\": float(results['arousal'][i]),\n",
    "                \"dominance\": float(results['dominance'][i]),\n",
    "                \"envelope\": {\n",
    "                    \"mean_amplitude\": float(results['envelope_segments'][i]['mean_amplitude']),\n",
    "                    \"max_amplitude\": float(results['envelope_segments'][i]['max_amplitude']),\n",
    "                    \"amplitude_std\": float(results['envelope_segments'][i]['amplitude_std'])\n",
    "                }\n",
    "            }\n",
    "            response_data[\"frames\"].append(frame_data)\n",
    "        \n",
    "        # Add full envelope data\n",
    "        response_data[\"full_envelope\"] = {\n",
    "            \"times\": results['full_envelope_times'].tolist(),\n",
    "            \"values\": results['full_envelope'].tolist()\n",
    "        }\n",
    "        \n",
    "        return JSONResponse(content=response_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Error processing audio: {str(e)}\")\n",
    "\n",
    "\n",
    "def download_official_model():\n",
    "    \"\"\"Download the official audEERING ONNX model (legacy function)\"\"\"\n",
    "    # This function is kept for compatibility but not used in optimized version\n",
    "    model_root = '/tmp/model'\n",
    "    cache_root = '/tmp/cache'\n",
    "    \n",
    "    os.makedirs(cache_root, exist_ok=True)\n",
    "    \n",
    "    def cache_path(file):\n",
    "        return os.path.join(cache_root, file)\n",
    "    \n",
    "    url = 'https://zenodo.org/record/6221127/files/w2v2-L-robust-12.6bc4a7fd-1.1.0.zip'\n",
    "    dst_path = cache_path('model.zip')\n",
    "    \n",
    "    if not os.path.exists(dst_path):\n",
    "        print(\"Downloading official model...\")\n",
    "        audeer.download_url(url, dst_path, verbose=True)\n",
    "    \n",
    "    if not os.path.exists(model_root):\n",
    "        print(\"Extracting model...\")\n",
    "        audeer.extract_archive(dst_path, model_root, verbose=True)\n",
    "    \n",
    "    return model_root\n",
    "\n",
    "\n",
    "def load_official_model():\n",
    "    \"\"\"Load the official ONNX model with multi-level caching\"\"\"\n",
    "    # Check if model is already cached in memory\n",
    "    if hasattr(load_official_model, '_cached_model'):\n",
    "        print(\"Using in-memory cached model\")\n",
    "        return load_official_model._cached_model\n",
    "    \n",
    "    print(\"Loading official model...\")\n",
    "    \n",
    "    # Try to use model from persistent volume first\n",
    "    persistent_model_path = \"/persistent_model/w2v2_model\"\n",
    "    if os.path.exists(persistent_model_path):\n",
    "        print(\"Using model from persistent volume\")\n",
    "        model_root = persistent_model_path\n",
    "    else:\n",
    "        # Fall back to model baked into image, then copy to persistent volume\n",
    "        print(\"Using model from image, copying to persistent volume...\")\n",
    "        image_model_path = \"/model_cache/model\"\n",
    "        if os.path.exists(image_model_path):\n",
    "            os.makedirs(\"/persistent_model\", exist_ok=True)\n",
    "            import shutil\n",
    "            shutil.copytree(image_model_path, persistent_model_path)\n",
    "            model_root = persistent_model_path\n",
    "            # Commit the volume to persist the model\n",
    "            model_volume.commit()\n",
    "        else:\n",
    "            # Last resort: download (shouldn't happen with image baking)\n",
    "            print(\"Downloading model as fallback...\")\n",
    "            model_root = download_official_model_fallback()\n",
    "    \n",
    "    model = audonnx.load(model_root)\n",
    "    \n",
    "    # Create interface for easier usage\n",
    "    interface = audinterface.Feature(\n",
    "        model.labels('logits'),\n",
    "        process_func=model,\n",
    "        process_func_args={'outputs': 'logits'},\n",
    "        sampling_rate=16000,\n",
    "        resample=True,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # Cache the loaded model in memory\n",
    "    load_official_model._cached_model = (model, interface)\n",
    "    print(\"Model loaded and cached successfully\")\n",
    "    \n",
    "    return model, interface\n",
    "\n",
    "\n",
    "def download_official_model_fallback():\n",
    "    \"\"\"Fallback model download function\"\"\"\n",
    "    model_root = '/persistent_model/w2v2_model'\n",
    "    cache_root = '/tmp/cache'\n",
    "    \n",
    "    os.makedirs(cache_root, exist_ok=True)\n",
    "    os.makedirs('/persistent_model', exist_ok=True)\n",
    "    \n",
    "    def cache_path(file):\n",
    "        return os.path.join(cache_root, file)\n",
    "    \n",
    "    url = 'https://zenodo.org/record/6221127/files/w2v2-L-robust-12.6bc4a7fd-1.1.0.zip'\n",
    "    dst_path = cache_path('model.zip')\n",
    "    \n",
    "    if not os.path.exists(dst_path):\n",
    "        print(\"Downloading official model...\")\n",
    "        audeer.download_url(url, dst_path, verbose=True)\n",
    "    \n",
    "    if not os.path.exists(model_root):\n",
    "        print(\"Extracting model...\")\n",
    "        audeer.extract_archive(dst_path, model_root, verbose=True)\n",
    "        # Commit to persistent volume\n",
    "        model_volume.commit()\n",
    "    \n",
    "    return model_root\n",
    "\n",
    "\n",
    "def predict_vad_official(audio, interface):\n",
    "    \"\"\"Predict VAD using official model\"\"\"\n",
    "    # Process audio\n",
    "    result = interface.process_signal(audio, 16000)\n",
    "    \n",
    "    # Extract values (result is a pandas DataFrame)\n",
    "    arousal = float(result['arousal'].iloc[0])\n",
    "    dominance = float(result['dominance'].iloc[0])\n",
    "    valence = float(result['valence'].iloc[0])\n",
    "    \n",
    "    return {\n",
    "        'arousal': arousal,\n",
    "        'dominance': dominance,\n",
    "        'valence': valence\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_audio_envelope(audio, sr=16000, hop_length=512):\n",
    "    \"\"\"Extract amplitude envelope from audio\"\"\"\n",
    "    rms_envelope = librosa.feature.rms(y=audio, hop_length=hop_length)[0]\n",
    "    envelope_times = librosa.frames_to_time(np.arange(len(rms_envelope)),\n",
    "                                           sr=sr, hop_length=hop_length)\n",
    "    return envelope_times, rms_envelope\n",
    "\n",
    "\n",
    "def predict_vad_frames_with_envelope_official(audio, interface, window_size=1.0, hop_size=0.25):\n",
    "    \"\"\"Predict VAD frame-by-frame using official model + extract envelope\"\"\"\n",
    "    sr = 16000\n",
    "    window_samples = int(window_size * sr)\n",
    "    hop_samples = int(hop_size * sr)\n",
    "    \n",
    "    vad_frames = []\n",
    "    envelope_segments = []\n",
    "    times = []\n",
    "    \n",
    "    # Extract full envelope\n",
    "    full_envelope_times, full_envelope = extract_audio_envelope(audio, sr)\n",
    "    \n",
    "    # Sliding window for VAD\n",
    "    for start in range(0, len(audio) - window_samples + 1, hop_samples):\n",
    "        end = start + window_samples\n",
    "        window_audio = audio[start:end]\n",
    "        \n",
    "        # Predict VAD for this window\n",
    "        vad = predict_vad_official(window_audio, interface)\n",
    "        vad_frames.append(vad)\n",
    "        \n",
    "        # Extract envelope for this segment\n",
    "        seg_times, seg_envelope = extract_audio_envelope(window_audio, sr)\n",
    "        envelope_segments.append({\n",
    "            'times': seg_times + (start / sr),\n",
    "            'envelope': seg_envelope,\n",
    "            'mean_amplitude': np.mean(seg_envelope),\n",
    "            'max_amplitude': np.max(seg_envelope),\n",
    "            'amplitude_std': np.std(seg_envelope)\n",
    "        })\n",
    "        \n",
    "        times.append(start / sr)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    arousal = [frame['arousal'] for frame in vad_frames]\n",
    "    dominance = [frame['dominance'] for frame in vad_frames] \n",
    "    valence = [frame['valence'] for frame in vad_frames]\n",
    "    \n",
    "    return {\n",
    "        'times': np.array(times),\n",
    "        'arousal': np.array(arousal),\n",
    "        'dominance': np.array(dominance),\n",
    "        'valence': np.array(valence),\n",
    "        'envelope_segments': envelope_segments,\n",
    "        'full_envelope_times': full_envelope_times,\n",
    "        'full_envelope': full_envelope,\n",
    "        'window_size': window_size,\n",
    "        'hop_size': hop_size\n",
    "    }\n",
    "\n",
    "\n",
    "# Add CORS middleware for Netlify app integration\n",
    "@app.function(image=image)\n",
    "@web_endpoint(method=\"GET\")\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\"status\": \"healthy\", \"message\": \"Voice Analysis API is running\"}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local testing\n",
    "    import modal\n",
    "    print(\"Deploy with: modal deploy modal_voice_analysis.py\")\n",
    "    print(\"\\nCost Optimization Notes:\")\n",
    "    print(\"- No keep_warm: Only pay when processing requests\")\n",
    "    print(\"- Cold start: ~5-10 seconds (model loads from persistent volume)\")\n",
    "    print(\"- Warm requests: ~100ms (model cached in memory)\")\n",
    "    print(\"- Instance auto-shuts down after idle period\")\n",
    "    print(\"\\nOptional: Add keep_warm=1 for production if you need <1s response times\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
